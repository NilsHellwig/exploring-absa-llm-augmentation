{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb99927-a103-43f1-83a3-a945c547b342",
   "metadata": {},
   "source": [
    "# Notebook: Create Synthetic Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32d2bd-049d-4bf6-9da7-3ef4bf665fef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "399c6d6b-93d8-43c6-bc92-b4777c79d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_synthesis import get_examples_as_text, xml_to_json, is_valid_xml, check_valid_aspect_xml, count_sentences_in_text, german_language_detected\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "from llama_cpp import Llama\n",
    "import random\n",
    "import openai\n",
    "import json\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba178e1d-cb71-4592-bc13-4117f199da2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcaa69-41c0-4e90-a522-f4d3915d16fe",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83965861-d5ac-4d59-a373-a26ca8743c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = 0\n",
    "MODEL_ID = 0\n",
    "FEW_SHOTS = \"fixed\" # \"fixed\" or \"random\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac519d5-7c23-4fd8-8bac-93b4f1b1f17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54dca12b-2965-4441-b1ce-48a1008a129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = f'../07 train classifier/real/split_{SPLIT}.json'\n",
    "LABELS_AND_EXAMPLES_PATH = f\"few_shot_examples/few_shot_examples_{FEW_SHOTS}.json\"\n",
    "\n",
    "# LLM Settings\n",
    "MAX_TOKENS = 250\n",
    "CONTEXT_SIZE = 4096\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "# Set Seed\n",
    "SEED = int(str(43) + str(SPLIT) + str(MODEL_ID))\n",
    "\n",
    "N_RETRIES = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7eaae3a2-87e7-4008-b715-f548b8312ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Classes/Polarities for Synthesis\n",
    "CLASSES  = [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "POLARITIES = [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]\n",
    "COMBINATIONS = [(aspect, polarity) for polarity in POLARITIES for aspect in CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9aef1ca2-4279-4d15-9157-54fa7093b95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STOP_CRITERIA = [\"Label:\", \"\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bbf5c9b-7f77-4466-99b8-fa1bc7fa51aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "243bd623-87d1-4448-9a42-600c9158dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\"Llama13B\", \"Llama70B\", \"Falcon40B\", \"GPT-3\"]\n",
    "# 175B, 70B und 40B\n",
    "MODEL_PATHS = {\"Llama13B\": \"llm_models/llama-2-13b.Q4_0.gguf\", \"Llama70B\": \"llm_models/llama-2-70b.Q4_0.gguf\", \"Falcon40B\": \"llm_models/falcon-40b-Q4_K_S.gguf\"}\n",
    "MODEL_NAME = MODELS[MODEL_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2424728-2345-46c6-b27b-116d203f869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTH_PATH = f\"../07 train classifier/synth/{MODEL_NAME}/{FEW_SHOTS}/split_{SPLIT}.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2231fc-6972-4230-ac87-32530d8a1418",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c44e0-b2ad-4e98-b48a-5c821b68b842",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff2483b2-621a-4f0e-86f3-a0d2ce921ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../prompt_template.txt', 'r') as file:\n",
    "    PROMPT_TEMPLATE = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e2452-ebd5-47e4-8b9a-bdd011ea139c",
   "metadata": {},
   "source": [
    "### Load Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "817d57c6-f670-446f-9014-706bf10ec4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(DATASET_PATH, 'r', encoding='utf-8') as json_file:\n",
    "    dataset = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040660c9-c758-4f82-82bc-17883d92f7f3",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "194f288c-533a-4776-aee8-91556516cd81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"Llama70B\":\n",
    "    llm = Llama(model_path=MODEL_PATHS[MODEL_NAME], seed=SEED, n_gpu_layers=1, n_ctx=CONTEXT_SIZE, verbose=False, n_gqa=8)\n",
    "    clear_output(wait=False)\n",
    "    def llm_model(text):\n",
    "        return llm(text, max_tokens=MAX_TOKENS, stop=STOP_CRITERIA, echo=True, top_p=1, temperature=TEMPERATURE)[\"choices\"][0][\"text\"][len(text):]\n",
    "    \n",
    "if MODEL_NAME == \"Llama13B\" or MODEL_NAME == \"Falcon40B\":\n",
    "    llm = Llama(model_path=MODEL_PATHS[MODEL_NAME], seed=SEED, n_gpu_layers=1, n_ctx=CONTEXT_SIZE, verbose=False)\n",
    "    clear_output(wait=False)\n",
    "    def llm_model(text):\n",
    "        return llm(text, max_tokens=MAX_TOKENS, stop=STOP_CRITERIA, echo=True, top_p=1, temperature=TEMPERATURE)[\"choices\"][0][\"text\"][len(text):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34d4e54d-0533-4d64-8a69-7383169293e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"GPT-3\":\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    def llm_model(text):\n",
    "        response = openai.ChatCompletion.create(\n",
    "           model=\"gpt-3.5-turbo\",\n",
    "           messages=[\n",
    "              {\"role\": \"user\", \"content\": text}\n",
    "           ],\n",
    "           max_tokens=MAX_TOKENS,  \n",
    "           temperature=TEMPERATURE, \n",
    "           stop=STOP_CRITERIA\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f0b6d-bf56-494b-b6ca-bc5d101b7b30",
   "metadata": {},
   "source": [
    "### Load Labels and Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c780171",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABELS_AND_EXAMPLES_PATH, 'r', encoding='utf-8') as json_file:\n",
    "    labels_and_examples = json.load(json_file)[f\"split_{SPLIT}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8350a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_and_examples[\"labels_for_prediction\"]\n",
    "labels = [[(aspect, polarity) for aspect, polarity in sub_list] for sub_list in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "161cf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = labels_and_examples[\"few_shot_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6f942-107e-4f86-b15f-b62413d94f7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Synthetic Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6cf3ee06-3bfa-4366-b8ba-6fdfec400a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6307db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current index: 0, n_retry: 0, text: Wir haben uns sehr wohl gefühlt, das <aspect-term aspect=\"GENERAL-IMPRESSION\" polarity=\"POSITIVE\">Ambiente</aspect-term> und die <aspect-term aspect=\"SERVICE\" polarity=\"POSITIVE\">Bedienung</aspect-term> waren top.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nils_hellwig/Desktop/Studium/Masterstudium WS 2023:24/Masterarbeit/absa-llm-augmentation/04 llm synthesis/02_create_synth.ipynb Zelle 28\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nils_hellwig/Desktop/Studium/Masterstudium%20WS%202023%3A24/Masterarbeit/absa-llm-augmentation/04%20llm%20synthesis/02_create_synth.ipynb#X42sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     no_german_language \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nils_hellwig/Desktop/Studium/Masterstudium%20WS%202023%3A24/Masterarbeit/absa-llm-augmentation/04%20llm%20synthesis/02_create_synth.ipynb#X42sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nils_hellwig/Desktop/Studium/Masterstudium%20WS%202023%3A24/Masterarbeit/absa-llm-augmentation/04%20llm%20synthesis/02_create_synth.ipynb#X42sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     synth_dataset[\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid4())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nils_hellwig/Desktop/Studium/Masterstudium%20WS%202023%3A24/Masterarbeit/absa-llm-augmentation/04%20llm%20synthesis/02_create_synth.ipynb#X42sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     synth_example[\u001b[39m\"\u001b[39m\u001b[39mllm_label\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m label\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nils_hellwig/Desktop/Studium/Masterstudium%20WS%202023%3A24/Masterarbeit/absa-llm-augmentation/04%20llm%20synthesis/02_create_synth.ipynb#X42sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     synth_example[\u001b[39m\"\u001b[39m\u001b[39mllm_examples\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m examples\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for idx, label in enumerate(labels):\n",
    "    # Setup Statistics\n",
    "    invalid_xml_schema = 0\n",
    "    invalid_xml_tags = 0\n",
    "    aspect_polarity_in_text_but_not_in_label = 0\n",
    "    more_than_one_sentences = 0\n",
    "    no_german_language = 0\n",
    "\n",
    "    # Setup JSON for new synth example\n",
    "    synth_example = {}\n",
    "    synth_example[\"llm_retry_statistic\"] = []\n",
    "\n",
    "    found_valid_example = False\n",
    "\n",
    "    # Alle 25 Beispielsets sollen 25 mal versucht werden\n",
    "    for new_example_idx in range(len(examples[str(idx)])):\n",
    "        for retry in range(N_RETRIES):\n",
    "            # new_example_idx will change in case it wasn't possible to generate a text for a given label after N_MAX_NEW_EXAMPLES retires\n",
    "            few_shot_examples = examples[str(idx)][f\"{new_example_idx}\"]\n",
    "            few_shot_examples = [\n",
    "                entry for entry in dataset if entry['id'] in few_shot_examples]\n",
    "\n",
    "            # Build Prompt\n",
    "            examples_text = get_examples_as_text(few_shot_examples)\n",
    "            prompt_footer = f'\\nLabel:{str(label)}\\nPrediction:'\n",
    "            prompt = PROMPT_TEMPLATE + examples_text + prompt_footer\n",
    "\n",
    "            # Execute LLM\n",
    "            prediction = llm_model(prompt)\n",
    "            \n",
    "            if is_valid_xml(f'<input>{prediction}</input>') == False:\n",
    "                invalid_xml_schema += 1\n",
    "            else:\n",
    "                if check_valid_aspect_xml(f'<input>{prediction}</input>') == False:\n",
    "                    invalid_xml_tags += 1\n",
    "                else:\n",
    "                    prediction_as_json = xml_to_json(\n",
    "                        prediction, label, MODEL_NAME, SPLIT)\n",
    "                    if prediction_as_json == \"not-in-label\":\n",
    "                        aspect_polarity_in_text_but_not_in_label += 1\n",
    "                    else:\n",
    "                        if count_sentences_in_text(prediction_as_json[\"text\"]) > 1:\n",
    "                            more_than_one_sentences += 1\n",
    "                        else:\n",
    "                            if german_language_detected(prediction_as_json[\"text\"]) == False:\n",
    "                                no_german_language += 1\n",
    "                            else:\n",
    "                                synth_dataset[\"id\"] = str(uuid.uuid4())\n",
    "                                synth_example[\"llm_label\"] = label\n",
    "                                synth_example[\"llm_examples\"] = examples\n",
    "                                synth_example[\"llm_prompt\"] = prompt\n",
    "                                synth_example[\"llm_invalid_xml_schema\"] = invalid_xml_schema\n",
    "                                synth_example[\"llm_invalid_xml_tags\"] = invalid_xml_tags\n",
    "                                synth_example[\"llm_aspect_polarity_in_text_but_not_in_label\"] = aspect_polarity_in_text_but_not_in_label\n",
    "                                synth_example[\"llm_more_than_one_sentences\"] = more_than_one_sentences\n",
    "                                synth_example[\"llm_no_german_language\"] = no_german_language\n",
    "                                for key in prediction_as_json.keys():\n",
    "                                    synth_example[key] = prediction_as_json[key]\n",
    "\n",
    "                                found_valid_example = True\n",
    "            \n",
    "            # Log current generation\n",
    "            print(f'current index: {idx}, n_retry: {len(synth_example[\"llm_retry_statistic\"])}, text: {prediction}')\n",
    "\n",
    "            if found_valid_example:\n",
    "                break\n",
    "            else:\n",
    "                # Save Statistics of retries\n",
    "                retry_statistic = {}\n",
    "                retry_statistic[\"llm_label\"] = label\n",
    "                retry_statistic[\"llm_examples\"] = examples\n",
    "                retry_statistic[\"llm_prompt\"] = prompt\n",
    "                retry_statistic[\"llm_invalid_xml_schema\"] = invalid_xml_schema\n",
    "                retry_statistic[\"llm_invalid_xml_tags\"] = invalid_xml_tags\n",
    "                retry_statistic[\"llm_aspect_polarity_in_text_but_not_in_label\"] = aspect_polarity_in_text_but_not_in_label\n",
    "                retry_statistic[\"llm_more_than_one_sentences\"] = more_than_one_sentences\n",
    "                retry_statistic[\"llm_no_german_language\"] = no_german_language\n",
    "                retry_statistic[\"llm_change_examples\"] = new_example_idx\n",
    "                retry_statistic[\"llm_retries_for_example_set\"] = retry\n",
    "                synth_example[\"llm_retry_statistic\"].append(retry_statistic)\n",
    "\n",
    "        if found_valid_example:\n",
    "            synth_dataset.append(synth_example)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b811e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ambiente ist sehr schön, Service leidet durch die große Anzahl der Gäste, aber das Essen war auch sehr gut.',\n",
       " [{'text': 'Essen',\n",
       "   'start': 83,\n",
       "   'end': 88,\n",
       "   'tag_with_polarity': 'FOOD-POSITIVE',\n",
       "   'tag_with_polarity_and_type': 'FOOD-POSITIVE-explicit',\n",
       "   'type': 'label-explicit',\n",
       "   'label': 'FOOD',\n",
       "   'polarity': 'POSITIVE'},\n",
       "  {'text': 'Service',\n",
       "   'start': 25,\n",
       "   'end': 32,\n",
       "   'tag_with_polarity': 'SERVICE-NEUTRAL',\n",
       "   'tag_with_polarity_and_type': 'SERVICE-NEUTRAL-explicit',\n",
       "   'type': 'label-explicit',\n",
       "   'label': 'SERVICE',\n",
       "   'polarity': 'NEUTRAL'},\n",
       "  {'text': None,\n",
       "   'start': 0,\n",
       "   'end': 0,\n",
       "   'tag_with_polarity': 'AMBIENCE-POSITIVE',\n",
       "   'tag_with_polarity_and_type': 'AMBIENCE-POSITIVE-implicit',\n",
       "   'type': 'label-implicit',\n",
       "   'label': 'AMBIENCE',\n",
       "   'polarity': 'POSITIVE'}])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_dataset[3][\"text\"], synth_dataset[3][\"tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85cd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(SYNTH_PATH), exist_ok=True)\n",
    "with open(SYNTH_PATH, \"w\") as outfile:\n",
    "    json.dump(synth_dataset, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
